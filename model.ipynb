{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# added\n",
    "from folder import KFolder\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from Augmentation import ToAugmantate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_plot(hist):\n",
    "    train_epochs = list(range(1, len(hist.history['loss']) + 1))\n",
    "    valid_epochs = list(range(1, len(hist.history['val_loss']) + 1))\n",
    "    train_losses = hist.history['loss']\n",
    "    valid_losses = hist.history['val_loss']\n",
    "\n",
    "    train_min_loss = min(dict(zip(train_epochs, train_losses)).items(), key=lambda x: x[1])\n",
    "    valid_min_loss = min(dict(zip(valid_epochs, valid_losses)).items(), key=lambda x: x[1])\n",
    "\n",
    "    plt.plot(train_epochs, hist.history['loss'], linewidth=1, color='blue', label='Training Loss')\n",
    "    plt.plot(train_min_loss[0], train_min_loss[1], color='black', marker='o',\n",
    "             label=f'Training Best Epoch - {train_min_loss[0]}')\n",
    "    plt.plot(valid_epochs, hist.history['val_loss'], linewidth=1, color='red', label='Validation Loss')\n",
    "    plt.plot(valid_min_loss[0], valid_min_loss[1], color='black', marker='o',\n",
    "             label=f'Validation Best Epoch - {valid_min_loss[0]}')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(label='Training & Validation Loss')\n",
    "    plt.xlabel(xlabel='Epochs')\n",
    "    plt.ylabel(ylabel='Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_plot(hist):\n",
    "  epochs = list(range(1, len(hist.history['accuracy']) + 1))\n",
    "\n",
    "  plt.plot(epochs, hist.history['accuracy'], marker='o', linewidth=1, label='Training Accuracy', color='blue')\n",
    "  plt.plot(epochs, hist.history['val_accuracy'], marker='o', linewidth=1, label='Validation Accuracy', color='red')\n",
    "  plt.title(label='Training & Validation Accuracy')\n",
    "  plt.legend(loc='best')\n",
    "  plt.xlabel(xlabel='Epochs')\n",
    "  plt.ylabel(ylabel='Accuracy')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = keras.models.Sequential(layers=[\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), input_shape=(150, 150, 3),\n",
    "            padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dropout(rate=0.2),\n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dense(units=4, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DON'T RUN EVERY TIME, ONLY IF U WANT TO SHUFFLE TRAIN <-> TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# output_dir = 'splitted_dataset'\n",
    "# if os.path.exists(output_dir):\n",
    "#    shutil.rmtree(output_dir, ignore_errors=True)\n",
    "\n",
    "# os.makedirs(output_dir)\n",
    "# import splitfolders\n",
    "# splitfolders.ratio('dataset', output=output_dir, seed=1337, ratio=(.9, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path: str, class_id: int) -> list:\n",
    "    content_list = os.listdir(path)\n",
    "    files_list = [os.path.join(path, content_thing) for content_thing in content_list if os.path.isfile(os.path.join(path, content_thing))]\n",
    "    imgs_list = []\n",
    "    labels_list = []\n",
    "    for file_path in files_list:\n",
    "        temp_img = Image.open(file_path)\n",
    "        numpy_image = np.asarray(temp_img.resize((150,150)))\n",
    "        imgs_list.append(numpy_image)\n",
    "        labels_list.append(class_id)\n",
    "    return np.array(imgs_list), np.array(labels_list)\n",
    "\n",
    "# load train images\n",
    "main_path = \"splitted_dataset/\"\n",
    "cataract = main_path+\"train/cataract\"\n",
    "diabetic_retinopathy = main_path+\"train/diabetic_retinopathy\"\n",
    "glaucoma = main_path+\"train/glaucoma\"\n",
    "normal = main_path+\"train/normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_cataract, labels_cataract = load_images(cataract, 1)\n",
    "images_diabetic_retinopathy, labels_retinopathy = load_images(diabetic_retinopathy, 2)\n",
    "images_glaucoma, labels_glaucoma = load_images(glaucoma, 3)\n",
    "images_normal, labels_normal = load_images(normal, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tables\n",
    "x = np.concatenate([images_cataract,images_diabetic_retinopathy,images_glaucoma,images_normal])\n",
    "y = np.concatenate([labels_cataract,labels_retinopathy,labels_glaucoma,labels_normal])\n",
    "del images_cataract, images_diabetic_retinopathy, images_glaucoma, images_normal, labels_cataract,labels_retinopathy,labels_glaucoma,labels_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_cataract, labels_cataract = load_images(cataract, 1)\n",
    "images_diabetic_retinopathy, labels_retinopathy = load_images(main_path+\"val/diabetic_retinopathy\", 2)\n",
    "images_glaucoma, labels_glaucoma = load_images(main_path+\"val/glaucoma\", 3)\n",
    "images_normal, labels_normal = load_images(main_path+\"val/normal\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate([images_cataract,images_diabetic_retinopathy,images_glaucoma,images_normal])\n",
    "Y_test = np.concatenate([labels_cataract,labels_retinopathy,labels_glaucoma,labels_normal])\n",
    "del images_cataract, images_diabetic_retinopathy, images_glaucoma, images_normal, labels_cataract,labels_retinopathy,labels_glaucoma,labels_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ToAugmantate()\n",
    "test_data_gen = ToAugmantate(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing folds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "kfolder = KFolder(3, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 09:06:26.774192: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-11 09:06:26.955298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-11 09:06:26.955357: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-11 09:06:26.962814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-11 09:06:26.962878: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-11 09:06:26.962902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-11 09:06:28.420449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-11 09:06:28.421060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-11 09:06:28.422017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-06-11 09:06:28.422127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-11 09:06:28.422887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-06-11 09:06:29.919229: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 682560000 exceeds 10% of free system memory.\n",
      "2023-06-11 09:06:30.818987: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 682560000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 09:06:52.358672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from dataset import get_data\n",
    "# from model import get_model\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import segmentation_models as sm\n",
    "# from folder import KFolder\n",
    "for i, fold in enumerate(kfolder.folds):\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(f\"./best_model_fold_{i}.h5\", save_best_only=True, verbose=1)]\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(\"./best_model.h5\", save_best_only=True, verbose=1)]\n",
    "    model = get_model()\n",
    "    model.compile(loss='mean_squared_logarithmic_error', optimizer='adam')\n",
    "\n",
    "    X_train, y_train, X_valid, y_valid = fold\n",
    "\n",
    "    model.fit(x=X_train, y=y_train, validation_data=(X_valid, y_valid), batch_size=2, epochs=100, callbacks=callbacks, verbose=1)\n",
    "\n",
    "    del model\n",
    "    best_model = tf.keras.models.load_model(f\"./best_model_fold_{i}.h5\")\n",
    "\n",
    "    evaluation = best_model.evaluate(X_test, Y_test)\n",
    "\n",
    "    with open(f\"./results_fold_{i}.txt\",'w') as f:\n",
    "        f.write(f\"test loss: {evaluation[0]}\\n\")\n",
    "        f.write(f\"accuracy: {evaluation[1]}\\n\")\n",
    "        f.write(f\"dice-score: {evaluation[2]}\\n\")\n",
    "    print(100*'--')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
