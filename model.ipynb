{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# added\n",
    "from folder import KFolder\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from Augmentation import ToAugmantate\n",
    "from shuffle import shuffle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_plot(hist):\n",
    "    train_epochs = list(range(1, len(hist.history['loss']) + 1))\n",
    "    valid_epochs = list(range(1, len(hist.history['val_loss']) + 1))\n",
    "    train_losses = hist.history['loss']\n",
    "    valid_losses = hist.history['val_loss']\n",
    "\n",
    "    train_min_loss = min(dict(zip(train_epochs, train_losses)).items(), key=lambda x: x[1])\n",
    "    valid_min_loss = min(dict(zip(valid_epochs, valid_losses)).items(), key=lambda x: x[1])\n",
    "\n",
    "    plt.plot(train_epochs, hist.history['loss'], linewidth=1, color='blue', label='Training Loss')\n",
    "    plt.plot(train_min_loss[0], train_min_loss[1], color='black', marker='o',\n",
    "             label=f'Training Best Epoch - {train_min_loss[0]}')\n",
    "    plt.plot(valid_epochs, hist.history['val_loss'], linewidth=1, color='red', label='Validation Loss')\n",
    "    plt.plot(valid_min_loss[0], valid_min_loss[1], color='black', marker='o',\n",
    "             label=f'Validation Best Epoch - {valid_min_loss[0]}')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(label='Training & Validation Loss')\n",
    "    plt.xlabel(xlabel='Epochs')\n",
    "    plt.ylabel(ylabel='Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_plot(hist):\n",
    "  epochs = list(range(1, len(hist.history['accuracy']) + 1))\n",
    "\n",
    "  plt.plot(epochs, hist.history['accuracy'], marker='o', linewidth=1, label='Training Accuracy', color='blue')\n",
    "  plt.plot(epochs, hist.history['val_accuracy'], marker='o', linewidth=1, label='Validation Accuracy', color='red')\n",
    "  plt.title(label='Training & Validation Accuracy')\n",
    "  plt.legend(loc='best')\n",
    "  plt.xlabel(xlabel='Epochs')\n",
    "  plt.ylabel(ylabel='Accuracy')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = keras.models.Sequential(layers=[\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), input_shape=(150, 150, 3),\n",
    "            padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dropout(rate=0.2),\n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dense(units=4, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DON'T RUN EVERY TIME, ONLY IF U WANT TO SHUFFLE TRAIN <-> TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# output_dir = 'splitted_dataset'\n",
    "# if os.path.exists(output_dir):\n",
    "#    shutil.rmtree(output_dir, ignore_errors=True)\n",
    "\n",
    "# os.makedirs(output_dir)\n",
    "# import splitfolders\n",
    "# splitfolders.ratio('dataset', output=output_dir, seed=1337, ratio=(.9, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path: str, class_id: int) -> list:\n",
    "    content_list = os.listdir(path)\n",
    "    files_list = [os.path.join(path, content_thing) for content_thing in content_list if os.path.isfile(os.path.join(path, content_thing))]\n",
    "    imgs_list = []\n",
    "    labels_list = []\n",
    "    for file_path in files_list:\n",
    "        temp_img = Image.open(file_path)\n",
    "        numpy_image = np.asarray(temp_img.resize((150,150)))\n",
    "        imgs_list.append(numpy_image)\n",
    "        labels_list.append(class_id)\n",
    "    return imgs_list, labels_list\n",
    "\n",
    "# load train images\n",
    "main_path = \"splitted_dataset/\"\n",
    "cataract = main_path+\"train/cataract\"\n",
    "diabetic_retinopathy = main_path+\"train/diabetic_retinopathy\"\n",
    "glaucoma = main_path+\"train/glaucoma\"\n",
    "normal = main_path+\"train/normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_cataract, labels_cataract = load_images(cataract, 1)\n",
    "images_diabetic_retinopathy, labels_retinopathy = load_images(diabetic_retinopathy, 2)\n",
    "images_glaucoma, labels_glaucoma = load_images(glaucoma, 3)\n",
    "images_normal, labels_normal = load_images(normal, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tables\n",
    "x = images_cataract+images_diabetic_retinopathy+images_glaucoma+images_normal\n",
    "y = labels_cataract+labels_retinopathy+labels_glaucoma+labels_normal\n",
    "x, y = shuffle_data(x, y)\n",
    "del images_cataract, images_diabetic_retinopathy, images_glaucoma, images_normal, labels_cataract,labels_retinopathy,labels_glaucoma,labels_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_cataract, labels_cataract = load_images(cataract, 1)\n",
    "images_diabetic_retinopathy, labels_retinopathy = load_images(main_path+\"val/diabetic_retinopathy\", 2)\n",
    "images_glaucoma, labels_glaucoma = load_images(main_path+\"val/glaucoma\", 3)\n",
    "images_normal, labels_normal = load_images(main_path+\"val/normal\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = images_cataract+images_diabetic_retinopathy+images_glaucoma+images_normal\n",
    "Y_test = labels_cataract+labels_retinopathy+labels_glaucoma+labels_normal\n",
    "X_test, Y_test = shuffle_data(X_test, Y_test)\n",
    "del images_cataract, images_diabetic_retinopathy, images_glaucoma, images_normal, labels_cataract,labels_retinopathy,labels_glaucoma,labels_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ToAugmantate()\n",
    "test_data_gen = ToAugmantate(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing folds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.01it/s]\n"
     ]
    }
   ],
   "source": [
    "kfolder = KFolder(5, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import tensorflow as tf\n",
    "# # from dataset import get_data\n",
    "# # from model import get_model\n",
    "# # import os\n",
    "# # import numpy as np\n",
    "# # import matplotlib.pyplot as plt\n",
    "# # import segmentation_models as sm\n",
    "# # from folder import KFolder\n",
    "# for i, fold in enumerate(kfolder.folds):\n",
    "#     callbacks = [tf.keras.callbacks.ModelCheckpoint(f\"./best_model_fold_{i}.h5\", save_best_only=True, verbose=1)]\n",
    "#     # callbacks = [tf.keras.callbacks.ModelCheckpoint(\"./best_model.h5\", save_best_only=True, verbose=1)]\n",
    "#     model = get_model()\n",
    "#     model.compile(loss='mean_squared_logarithmic_error', optimizer='adam')\n",
    "\n",
    "#     X_train, y_train, X_valid, y_valid = fold\n",
    "\n",
    "#     model.fit(train_data_gen.flow(X_train, y=y_train, batch_size=8, subset='training'), validation_data=(train_data_gen.flow(X_valid, y_valid, batch_size=8, subset='validation')), batch_size=16, epochs=100, callbacks=callbacks, verbose=1)\n",
    "\n",
    "#     del model\n",
    "#     best_model = tf.keras.models.load_model(f\"./best_model_fold_{i}.h5\")\n",
    "\n",
    "#     evaluation = best_model.evaluate(X_test, Y_test)\n",
    "\n",
    "#     with open(f\"./results_fold_{i}.txt\",'w') as f:\n",
    "#         f.write(f\"test loss: {evaluation[0]}\\n\")\n",
    "#         f.write(f\"accuracy: {evaluation[1]}\\n\")\n",
    "#         f.write(f\"dice-score: {evaluation[2]}\\n\")\n",
    "#     print(100*'--')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below presented by Chat GPT, bc above was giving error I had no clue why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Epoch 1/35\n",
      "95/95 [==============================] - 26s 263ms/step - loss: 2.1735 - categorical_accuracy: 0.3001 - val_loss: 0.7140 - val_categorical_accuracy: 0.3747 - lr: 3.0000e-04\n",
      "Epoch 2/35\n",
      "95/95 [==============================] - 23s 241ms/step - loss: 0.6521 - categorical_accuracy: 0.3011 - val_loss: 0.7997 - val_categorical_accuracy: 0.0013 - lr: 3.0000e-04\n",
      "Epoch 3/35\n",
      "95/95 [==============================] - 23s 247ms/step - loss: 0.5950 - categorical_accuracy: 0.2886 - val_loss: 0.5090 - val_categorical_accuracy: 0.1992 - lr: 3.0000e-04\n",
      "Epoch 4/35\n",
      "95/95 [==============================] - 23s 247ms/step - loss: 0.5118 - categorical_accuracy: 0.2876 - val_loss: 0.4537 - val_categorical_accuracy: 0.2177 - lr: 3.0000e-04\n",
      "Epoch 5/35\n",
      "95/95 [==============================] - 23s 240ms/step - loss: 0.5017 - categorical_accuracy: 0.2886 - val_loss: 0.4184 - val_categorical_accuracy: 0.2863 - lr: 3.0000e-04\n",
      "Epoch 6/35\n",
      "95/95 [==============================] - 23s 241ms/step - loss: 0.4388 - categorical_accuracy: 0.2902 - val_loss: 0.4103 - val_categorical_accuracy: 0.2520 - lr: 3.0000e-04\n",
      "Epoch 7/35\n",
      "95/95 [==============================] - 23s 237ms/step - loss: 0.4082 - categorical_accuracy: 0.2889 - val_loss: 0.4124 - val_categorical_accuracy: 0.2929 - lr: 3.0000e-04\n",
      "Epoch 8/35\n",
      "95/95 [==============================] - 23s 237ms/step - loss: 0.3824 - categorical_accuracy: 0.2876 - val_loss: 0.4072 - val_categorical_accuracy: 0.2916 - lr: 3.0000e-04\n",
      "Epoch 9/35\n",
      "95/95 [==============================] - 23s 239ms/step - loss: 0.3799 - categorical_accuracy: 0.2863 - val_loss: 0.4215 - val_categorical_accuracy: 0.1702 - lr: 3.0000e-04\n",
      "Epoch 10/35\n",
      "95/95 [==============================] - 22s 233ms/step - loss: 0.3773 - categorical_accuracy: 0.2916 - val_loss: 0.3749 - val_categorical_accuracy: 0.2757 - lr: 3.0000e-04\n",
      "Epoch 11/35\n",
      "95/95 [==============================] - 22s 233ms/step - loss: 0.3485 - categorical_accuracy: 0.2833 - val_loss: 0.3616 - val_categorical_accuracy: 0.3034 - lr: 3.0000e-04\n",
      "Epoch 12/35\n",
      "95/95 [==============================] - 23s 239ms/step - loss: 0.3371 - categorical_accuracy: 0.2886 - val_loss: 0.3904 - val_categorical_accuracy: 0.2150 - lr: 3.0000e-04\n",
      "Epoch 13/35\n",
      "95/95 [==============================] - 23s 238ms/step - loss: 0.3137 - categorical_accuracy: 0.2840 - val_loss: 0.3925 - val_categorical_accuracy: 0.3008 - lr: 3.0000e-04\n",
      "Epoch 14/35\n",
      "95/95 [==============================] - 22s 232ms/step - loss: 0.2550 - categorical_accuracy: 0.2850 - val_loss: 0.3335 - val_categorical_accuracy: 0.2850 - lr: 6.0000e-05\n",
      "Epoch 15/35\n",
      "95/95 [==============================] - 22s 236ms/step - loss: 0.2389 - categorical_accuracy: 0.2820 - val_loss: 0.3236 - val_categorical_accuracy: 0.2533 - lr: 6.0000e-05\n",
      "Epoch 16/35\n",
      "95/95 [==============================] - 22s 234ms/step - loss: 0.2139 - categorical_accuracy: 0.2807 - val_loss: 0.3288 - val_categorical_accuracy: 0.2256 - lr: 6.0000e-05\n",
      "Epoch 17/35\n",
      "95/95 [==============================] - 22s 233ms/step - loss: 0.2259 - categorical_accuracy: 0.2777 - val_loss: 0.3248 - val_categorical_accuracy: 0.2744 - lr: 6.0000e-05\n",
      "Epoch 18/35\n",
      "95/95 [==============================] - 23s 238ms/step - loss: 0.2046 - categorical_accuracy: 0.2784 - val_loss: 0.3144 - val_categorical_accuracy: 0.2784 - lr: 1.2000e-05\n",
      "Epoch 19/35\n",
      "95/95 [==============================] - 22s 234ms/step - loss: 0.1971 - categorical_accuracy: 0.2810 - val_loss: 0.3094 - val_categorical_accuracy: 0.2586 - lr: 1.2000e-05\n",
      "Epoch 20/35\n",
      "95/95 [==============================] - 22s 236ms/step - loss: 0.1928 - categorical_accuracy: 0.2800 - val_loss: 0.3131 - val_categorical_accuracy: 0.2573 - lr: 1.2000e-05\n",
      "Epoch 21/35\n",
      "95/95 [==============================] - 22s 234ms/step - loss: 0.1906 - categorical_accuracy: 0.2744 - val_loss: 0.3240 - val_categorical_accuracy: 0.2586 - lr: 1.2000e-05\n",
      "Epoch 22/35\n",
      "95/95 [==============================] - 22s 232ms/step - loss: 0.1872 - categorical_accuracy: 0.2833 - val_loss: 0.3221 - val_categorical_accuracy: 0.2625 - lr: 2.4000e-06\n",
      "24/24 [==============================] - 2s 64ms/step - loss: 0.3160 - categorical_accuracy: 0.2573\n",
      "Fold Loss: 0.3159792423248291\n",
      "Fold Accuracy: 0.2572559416294098\n",
      "Fold: 2\n",
      "Epoch 1/35\n",
      "95/95 [==============================] - 24s 242ms/step - loss: 2.8639 - categorical_accuracy: 0.3055 - val_loss: 0.8560 - val_categorical_accuracy: 0.0778 - lr: 3.0000e-04\n",
      "Epoch 2/35\n",
      "95/95 [==============================] - 23s 239ms/step - loss: 0.6490 - categorical_accuracy: 0.2896 - val_loss: 0.6491 - val_categorical_accuracy: 0.2282 - lr: 3.0000e-04\n",
      "Epoch 3/35\n",
      "95/95 [==============================] - 22s 235ms/step - loss: 0.5375 - categorical_accuracy: 0.2840 - val_loss: 0.4533 - val_categorical_accuracy: 0.3047 - lr: 3.0000e-04\n",
      "Epoch 4/35\n",
      "95/95 [==============================] - 23s 239ms/step - loss: 0.5110 - categorical_accuracy: 0.2856 - val_loss: 0.4362 - val_categorical_accuracy: 0.2520 - lr: 3.0000e-04\n",
      "Epoch 5/35\n",
      "95/95 [==============================] - 23s 238ms/step - loss: 0.4584 - categorical_accuracy: 0.2810 - val_loss: 0.4202 - val_categorical_accuracy: 0.2810 - lr: 3.0000e-04\n",
      "Epoch 6/35\n",
      "95/95 [==============================] - 22s 235ms/step - loss: 0.4373 - categorical_accuracy: 0.2830 - val_loss: 0.3678 - val_categorical_accuracy: 0.2704 - lr: 3.0000e-04\n",
      "Epoch 7/35\n",
      "95/95 [==============================] - 22s 234ms/step - loss: 0.4101 - categorical_accuracy: 0.2817 - val_loss: 0.3704 - val_categorical_accuracy: 0.2836 - lr: 3.0000e-04\n",
      "Epoch 8/35\n",
      "95/95 [==============================] - 22s 237ms/step - loss: 0.3789 - categorical_accuracy: 0.2843 - val_loss: 0.4480 - val_categorical_accuracy: 0.2770 - lr: 3.0000e-04\n",
      "Epoch 9/35\n",
      "95/95 [==============================] - 22s 234ms/step - loss: 0.3374 - categorical_accuracy: 0.2859 - val_loss: 0.3370 - val_categorical_accuracy: 0.2797 - lr: 6.0000e-05\n",
      "Epoch 10/35\n",
      "95/95 [==============================] - 22s 232ms/step - loss: 0.3060 - categorical_accuracy: 0.2859 - val_loss: 0.3284 - val_categorical_accuracy: 0.2902 - lr: 6.0000e-05\n",
      "Epoch 11/35\n",
      "95/95 [==============================] - 24s 255ms/step - loss: 0.2958 - categorical_accuracy: 0.2833 - val_loss: 0.3498 - val_categorical_accuracy: 0.2836 - lr: 6.0000e-05\n",
      "Epoch 12/35\n",
      "95/95 [==============================] - 24s 249ms/step - loss: 0.2865 - categorical_accuracy: 0.2836 - val_loss: 0.3273 - val_categorical_accuracy: 0.3008 - lr: 6.0000e-05\n",
      "Epoch 13/35\n",
      "95/95 [==============================] - 24s 250ms/step - loss: 0.2820 - categorical_accuracy: 0.2836 - val_loss: 0.3361 - val_categorical_accuracy: 0.2652 - lr: 6.0000e-05\n",
      "Epoch 14/35\n",
      "95/95 [==============================] - 27s 284ms/step - loss: 0.2668 - categorical_accuracy: 0.2856 - val_loss: 0.3305 - val_categorical_accuracy: 0.2889 - lr: 6.0000e-05\n",
      "Epoch 15/35\n",
      "95/95 [==============================] - 24s 255ms/step - loss: 0.2431 - categorical_accuracy: 0.2840 - val_loss: 0.2948 - val_categorical_accuracy: 0.2889 - lr: 1.2000e-05\n",
      "Epoch 16/35\n",
      "95/95 [==============================] - 25s 259ms/step - loss: 0.2468 - categorical_accuracy: 0.2797 - val_loss: 0.3011 - val_categorical_accuracy: 0.2876 - lr: 1.2000e-05\n",
      "Epoch 17/35\n",
      "95/95 [==============================] - 24s 250ms/step - loss: 0.2305 - categorical_accuracy: 0.2810 - val_loss: 0.3003 - val_categorical_accuracy: 0.2916 - lr: 1.2000e-05\n",
      "Epoch 18/35\n",
      "95/95 [==============================] - 24s 253ms/step - loss: 0.2301 - categorical_accuracy: 0.2800 - val_loss: 0.2947 - val_categorical_accuracy: 0.2889 - lr: 2.4000e-06\n",
      "Epoch 19/35\n",
      "95/95 [==============================] - 26s 275ms/step - loss: 0.2269 - categorical_accuracy: 0.2794 - val_loss: 0.2925 - val_categorical_accuracy: 0.2916 - lr: 2.4000e-06\n",
      "Epoch 20/35\n",
      "95/95 [==============================] - 24s 253ms/step - loss: 0.2291 - categorical_accuracy: 0.2784 - val_loss: 0.2989 - val_categorical_accuracy: 0.2916 - lr: 2.4000e-06\n",
      "Epoch 21/35\n",
      "95/95 [==============================] - 24s 255ms/step - loss: 0.2225 - categorical_accuracy: 0.2853 - val_loss: 0.3020 - val_categorical_accuracy: 0.2863 - lr: 2.4000e-06\n",
      "Epoch 22/35\n",
      "95/95 [==============================] - 25s 259ms/step - loss: 0.2300 - categorical_accuracy: 0.2810 - val_loss: 0.3008 - val_categorical_accuracy: 0.2889 - lr: 4.8000e-07\n",
      "24/24 [==============================] - 2s 72ms/step - loss: 0.2967 - categorical_accuracy: 0.2889\n",
      "Fold Loss: 0.2967391014099121\n",
      "Fold Accuracy: 0.2889181971549988\n",
      "Fold: 3\n",
      "Epoch 1/35\n",
      "95/95 [==============================] - 25s 255ms/step - loss: 3.3533 - categorical_accuracy: 0.3055 - val_loss: 0.7646 - val_categorical_accuracy: 0.4749 - lr: 3.0000e-04\n",
      "Epoch 2/35\n",
      "95/95 [==============================] - 24s 255ms/step - loss: 0.6954 - categorical_accuracy: 0.3080 - val_loss: 0.6150 - val_categorical_accuracy: 0.1966 - lr: 3.0000e-04\n",
      "Epoch 3/35\n",
      "95/95 [==============================] - 24s 248ms/step - loss: 0.5931 - categorical_accuracy: 0.2863 - val_loss: 0.5423 - val_categorical_accuracy: 0.3034 - lr: 3.0000e-04\n",
      "Epoch 4/35\n",
      "95/95 [==============================] - 24s 251ms/step - loss: 0.5357 - categorical_accuracy: 0.2803 - val_loss: 0.5191 - val_categorical_accuracy: 0.2032 - lr: 3.0000e-04\n",
      "Epoch 5/35\n",
      "95/95 [==============================] - 25s 259ms/step - loss: 0.4815 - categorical_accuracy: 0.2916 - val_loss: 0.4671 - val_categorical_accuracy: 0.2625 - lr: 3.0000e-04\n",
      "Epoch 6/35\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 0.4376 - categorical_accuracy: 0.2873 - val_loss: 0.5055 - val_categorical_accuracy: 0.1491 - lr: 3.0000e-04\n",
      "Epoch 7/35\n",
      "95/95 [==============================] - 26s 268ms/step - loss: 0.4220 - categorical_accuracy: 0.2909 - val_loss: 0.4448 - val_categorical_accuracy: 0.2639 - lr: 3.0000e-04\n",
      "Epoch 8/35\n",
      "95/95 [==============================] - 26s 272ms/step - loss: 0.4032 - categorical_accuracy: 0.2916 - val_loss: 0.4074 - val_categorical_accuracy: 0.2639 - lr: 3.0000e-04\n",
      "Epoch 9/35\n",
      "95/95 [==============================] - 25s 264ms/step - loss: 0.3942 - categorical_accuracy: 0.2942 - val_loss: 0.4243 - val_categorical_accuracy: 0.3232 - lr: 3.0000e-04\n",
      "Epoch 10/35\n",
      "95/95 [==============================] - 26s 273ms/step - loss: 0.3614 - categorical_accuracy: 0.2939 - val_loss: 0.4419 - val_categorical_accuracy: 0.2111 - lr: 3.0000e-04\n",
      "Epoch 11/35\n",
      "95/95 [==============================] - 28s 290ms/step - loss: 0.3064 - categorical_accuracy: 0.2879 - val_loss: 0.4137 - val_categorical_accuracy: 0.2190 - lr: 6.0000e-05\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.4087 - categorical_accuracy: 0.2718\n",
      "Fold Loss: 0.40866073966026306\n",
      "Fold Accuracy: 0.27176782488822937\n",
      "Fold: 4\n",
      "Epoch 1/35\n",
      "95/95 [==============================] - 28s 286ms/step - loss: 2.7403 - categorical_accuracy: 0.3111 - val_loss: 0.7751 - val_categorical_accuracy: 0.4169 - lr: 3.0000e-04\n",
      "Epoch 2/35\n",
      "95/95 [==============================] - 24s 253ms/step - loss: 0.6780 - categorical_accuracy: 0.2995 - val_loss: 0.7342 - val_categorical_accuracy: 0.3311 - lr: 3.0000e-04\n",
      "Epoch 3/35\n",
      "95/95 [==============================] - 24s 253ms/step - loss: 0.5688 - categorical_accuracy: 0.2899 - val_loss: 0.5735 - val_categorical_accuracy: 0.3760 - lr: 3.0000e-04\n",
      "Epoch 4/35\n",
      "95/95 [==============================] - 24s 254ms/step - loss: 0.5239 - categorical_accuracy: 0.2886 - val_loss: 0.5512 - val_categorical_accuracy: 0.3417 - lr: 3.0000e-04\n",
      "Epoch 5/35\n",
      "95/95 [==============================] - 23s 245ms/step - loss: 0.4730 - categorical_accuracy: 0.2889 - val_loss: 0.5533 - val_categorical_accuracy: 0.3298 - lr: 3.0000e-04\n",
      "Epoch 6/35\n",
      "95/95 [==============================] - 23s 244ms/step - loss: 0.4358 - categorical_accuracy: 0.2866 - val_loss: 0.4857 - val_categorical_accuracy: 0.3087 - lr: 3.0000e-04\n",
      "Epoch 7/35\n",
      "95/95 [==============================] - 23s 244ms/step - loss: 0.4010 - categorical_accuracy: 0.2985 - val_loss: 0.4303 - val_categorical_accuracy: 0.2770 - lr: 3.0000e-04\n",
      "Epoch 8/35\n",
      "95/95 [==============================] - 24s 256ms/step - loss: 0.3653 - categorical_accuracy: 0.2883 - val_loss: 0.4646 - val_categorical_accuracy: 0.3562 - lr: 3.0000e-04\n",
      "Epoch 9/35\n",
      "95/95 [==============================] - 23s 242ms/step - loss: 0.3671 - categorical_accuracy: 0.2906 - val_loss: 0.4465 - val_categorical_accuracy: 0.3206 - lr: 3.0000e-04\n",
      "Epoch 10/35\n",
      "95/95 [==============================] - 23s 242ms/step - loss: 0.3017 - categorical_accuracy: 0.2935 - val_loss: 0.3894 - val_categorical_accuracy: 0.2929 - lr: 6.0000e-05\n",
      "Epoch 11/35\n",
      "95/95 [==============================] - 23s 244ms/step - loss: 0.2887 - categorical_accuracy: 0.2873 - val_loss: 0.4126 - val_categorical_accuracy: 0.3219 - lr: 6.0000e-05\n",
      "Epoch 12/35\n",
      "95/95 [==============================] - 23s 241ms/step - loss: 0.2787 - categorical_accuracy: 0.2896 - val_loss: 0.3973 - val_categorical_accuracy: 0.3298 - lr: 6.0000e-05\n",
      "Epoch 13/35\n",
      "95/95 [==============================] - 23s 238ms/step - loss: 0.2536 - categorical_accuracy: 0.2968 - val_loss: 0.3786 - val_categorical_accuracy: 0.2850 - lr: 1.2000e-05\n",
      "Epoch 14/35\n",
      "95/95 [==============================] - 23s 242ms/step - loss: 0.2565 - categorical_accuracy: 0.2846 - val_loss: 0.3756 - val_categorical_accuracy: 0.3100 - lr: 1.2000e-05\n",
      "Epoch 15/35\n",
      "95/95 [==============================] - 24s 248ms/step - loss: 0.2493 - categorical_accuracy: 0.2879 - val_loss: 0.3900 - val_categorical_accuracy: 0.3219 - lr: 1.2000e-05\n",
      "Epoch 16/35\n",
      "95/95 [==============================] - 23s 244ms/step - loss: 0.2473 - categorical_accuracy: 0.2859 - val_loss: 0.3730 - val_categorical_accuracy: 0.2902 - lr: 1.2000e-05\n",
      "Epoch 17/35\n",
      "95/95 [==============================] - 23s 243ms/step - loss: 0.2428 - categorical_accuracy: 0.2859 - val_loss: 0.3846 - val_categorical_accuracy: 0.3087 - lr: 1.2000e-05\n",
      "Epoch 18/35\n",
      "95/95 [==============================] - 24s 249ms/step - loss: 0.2364 - categorical_accuracy: 0.2869 - val_loss: 0.3770 - val_categorical_accuracy: 0.3034 - lr: 1.2000e-05\n",
      "Epoch 19/35\n",
      "95/95 [==============================] - 23s 240ms/step - loss: 0.2385 - categorical_accuracy: 0.2879 - val_loss: 0.3804 - val_categorical_accuracy: 0.2929 - lr: 2.4000e-06\n",
      "24/24 [==============================] - 2s 65ms/step - loss: 0.3714 - categorical_accuracy: 0.2876\n",
      "Fold Loss: 0.3713546693325043\n",
      "Fold Accuracy: 0.28759893774986267\n",
      "Fold: 5\n",
      "Epoch 1/35\n",
      "95/95 [==============================] - 25s 250ms/step - loss: 2.7778 - categorical_accuracy: 0.3113 - val_loss: 0.7478 - val_categorical_accuracy: 0.4090 - lr: 3.0000e-04\n",
      "Epoch 2/35\n",
      "95/95 [==============================] - 23s 242ms/step - loss: 0.6717 - categorical_accuracy: 0.3034 - val_loss: 0.6442 - val_categorical_accuracy: 0.2770 - lr: 3.0000e-04\n",
      "Epoch 3/35\n",
      "95/95 [==============================] - 23s 245ms/step - loss: 0.5802 - categorical_accuracy: 0.2794 - val_loss: 0.4886 - val_categorical_accuracy: 0.3074 - lr: 3.0000e-04\n",
      "Epoch 4/35\n",
      "95/95 [==============================] - 23s 245ms/step - loss: 0.4861 - categorical_accuracy: 0.2827 - val_loss: 0.4740 - val_categorical_accuracy: 0.2770 - lr: 3.0000e-04\n",
      "Epoch 5/35\n",
      "95/95 [==============================] - 23s 247ms/step - loss: 0.4523 - categorical_accuracy: 0.2731 - val_loss: 0.5501 - val_categorical_accuracy: 0.4261 - lr: 3.0000e-04\n",
      "Epoch 6/35\n",
      "95/95 [==============================] - 23s 241ms/step - loss: 0.4209 - categorical_accuracy: 0.2863 - val_loss: 0.4979 - val_categorical_accuracy: 0.2744 - lr: 3.0000e-04\n",
      "Epoch 7/35\n",
      "95/95 [==============================] - 23s 246ms/step - loss: 0.3618 - categorical_accuracy: 0.2770 - val_loss: 0.3731 - val_categorical_accuracy: 0.3285 - lr: 6.0000e-05\n",
      "Epoch 8/35\n",
      "95/95 [==============================] - 23s 241ms/step - loss: 0.3232 - categorical_accuracy: 0.2751 - val_loss: 0.3749 - val_categorical_accuracy: 0.3483 - lr: 6.0000e-05\n",
      "Epoch 9/35\n",
      "95/95 [==============================] - 23s 244ms/step - loss: 0.3110 - categorical_accuracy: 0.2790 - val_loss: 0.3496 - val_categorical_accuracy: 0.3087 - lr: 6.0000e-05\n",
      "Epoch 10/35\n",
      "95/95 [==============================] - 23s 241ms/step - loss: 0.3119 - categorical_accuracy: 0.2737 - val_loss: 0.3526 - val_categorical_accuracy: 0.3417 - lr: 6.0000e-05\n",
      "Epoch 11/35\n",
      "95/95 [==============================] - 23s 242ms/step - loss: 0.2940 - categorical_accuracy: 0.2681 - val_loss: 0.3456 - val_categorical_accuracy: 0.3311 - lr: 6.0000e-05\n",
      "Epoch 12/35\n",
      "95/95 [==============================] - 23s 241ms/step - loss: 0.2859 - categorical_accuracy: 0.2784 - val_loss: 0.3349 - val_categorical_accuracy: 0.3153 - lr: 6.0000e-05\n",
      "Epoch 13/35\n",
      "95/95 [==============================] - 23s 242ms/step - loss: 0.2765 - categorical_accuracy: 0.2751 - val_loss: 0.3307 - val_categorical_accuracy: 0.2968 - lr: 6.0000e-05\n",
      "Epoch 14/35\n",
      "95/95 [==============================] - 23s 242ms/step - loss: 0.2701 - categorical_accuracy: 0.2774 - val_loss: 0.3632 - val_categorical_accuracy: 0.3219 - lr: 6.0000e-05\n",
      "Epoch 15/35\n",
      "95/95 [==============================] - 23s 246ms/step - loss: 0.2701 - categorical_accuracy: 0.2724 - val_loss: 0.3442 - val_categorical_accuracy: 0.3285 - lr: 6.0000e-05\n",
      "Epoch 16/35\n",
      "95/95 [==============================] - 23s 241ms/step - loss: 0.2286 - categorical_accuracy: 0.2714 - val_loss: 0.3155 - val_categorical_accuracy: 0.3311 - lr: 1.2000e-05\n",
      "Epoch 17/35\n",
      "95/95 [==============================] - 23s 242ms/step - loss: 0.2305 - categorical_accuracy: 0.2734 - val_loss: 0.3273 - val_categorical_accuracy: 0.3153 - lr: 1.2000e-05\n",
      "Epoch 18/35\n",
      "95/95 [==============================] - 23s 247ms/step - loss: 0.2307 - categorical_accuracy: 0.2672 - val_loss: 0.3191 - val_categorical_accuracy: 0.3245 - lr: 1.2000e-05\n",
      "Epoch 19/35\n",
      "95/95 [==============================] - 23s 245ms/step - loss: 0.2172 - categorical_accuracy: 0.2714 - val_loss: 0.3176 - val_categorical_accuracy: 0.3259 - lr: 2.4000e-06\n",
      "24/24 [==============================] - 2s 69ms/step - loss: 0.3221 - categorical_accuracy: 0.3351\n",
      "Fold Loss: 0.32212579250335693\n",
      "Fold Accuracy: 0.33509233593940735\n",
      "Best Model Loss for each fold: [0.3159792423248291, 0.2967391014099121, 0.40866073966026306, 0.3713546693325043, 0.32212579250335693]\n",
      "Best Model Accuracy for each fold: [0.2572559416294098, 0.2889181971549988, 0.27176782488822937, 0.28759893774986267, 0.33509233593940735]\n",
      "Best Model saved as 'best_model.h5'\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_model_loss = float('inf')\n",
    "best_model_fold_loss = []\n",
    "best_model_accuracy = 0.0\n",
    "best_model_fold_accuracy = []\n",
    "\n",
    "for fold_idx, (x_train, y_train, x_valid, y_valid) in enumerate(kfolder.folds):\n",
    "    print(\"Fold:\", fold_idx + 1)\n",
    "    model = get_model()\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0003)\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Define callbacks\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_data_gen.flow(x_train, y_train, batch_size=32),\n",
    "                        epochs=35,\n",
    "                        validation_data=test_data_gen.flow(x_valid, y_valid),\n",
    "                        callbacks=[early_stopping, reduce_lr],\n",
    "                        verbose=1)\n",
    "\n",
    "    # Evaluate the model on validation data\n",
    "    loss, accuracy = model.evaluate(test_data_gen.flow(x_valid, y_valid))\n",
    "    print(\"Fold Loss:\", loss)\n",
    "    print(\"Fold Accuracy:\", accuracy)\n",
    "\n",
    "    # Save the best model for this fold\n",
    "    if loss < best_model_loss:\n",
    "        best_model = model\n",
    "        best_model_loss = loss\n",
    "    best_model_fold_loss.append(loss)\n",
    "    best_model_fold_accuracy.append(accuracy)\n",
    "\n",
    "# Print the best model's loss and accuracy for each fold\n",
    "print(\"Best Model Loss for each fold:\", best_model_fold_loss)\n",
    "print(\"Best Model Accuracy for each fold:\", best_model_fold_accuracy)\n",
    "\n",
    "# Save the best overall model\n",
    "best_model.save('best_model.h5')\n",
    "print(\"Best Model saved as 'best_model.h5'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
